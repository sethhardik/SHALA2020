# SHALA2020

Assignments for SHALA 2020(Stay Home and Learn AI), a volunteer effort by IITB faculty.

## Course Link
https://shala2020.github.io/
## Topic
|Assignment |	Content|
|---------------------------|--------------------------------------------------------------------------------------------------|
|Getting started | Python data structure, Loops, Classes, Linear Algebra|
|Basic data understanding:| Data science, Central tendency, Plots, Cumulative distribution|
|Improving plots |Different types of plots, How to customize plots|
|Basic statistics |Maximum likelihood estimation, sufficient statistics, null hypothesis testing, t-test, Wilcoxon rank test|
|Introduction to ML | Machine learning problems, parameter vs. hyperparameter, overfitting, training, validation, testing, cross-validation, regularization|
|Decision Trees |Definition of a decision tree, metrics of impurity, greedy algorithm to split a node, tree depth and pruning, ensemble of trees (random forest)|
|Bayesian decision theory |Bayes rule: Prior, likelihood, posterior, evidence, Gaussian density, sufficient statistics, maximum likelihood derivation for mean and covariance|
|Linear models  |linear regression and its analytical solution, loss function, gradient descent and learning rate, logistic regression and its cost, SVM hinge loss with L2 penalty|
|Kernelization |Dual form of an SVM, kernels for a dual form, examples of kernels and their typical uses, SVR in primal form, SVR in dual form|
|Feature selection and engineering | Normalization, text analysis, T-test, forward selection, features for images, features for audio, features for images, features for NLP, PCA, ZCA, K-PCA|
|Dense and shallow neural networks | Logistic regression as a sigmoid, single hidden layer using sigmoid and ReLU, approximation of any function using a single hidden layer, overfitting, advantage of multiple hidden layers, neural networks for regression, multi-regression, multi-classification using softmax, back propagation.|
|Advanced topics in neural networks| Weight initialization, momentum, weight decay, early stopping, batch SGD, advanced optimizers such as RMSprop and ADAM|
|Clustering |K-means, DB-SCAN, agglomerative clustering, scaling of dimensions, goodness of clustering|
